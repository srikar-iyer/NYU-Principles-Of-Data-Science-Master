{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, kstest\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "seed = 18752360\n",
    "dfmain = pd.read_csv(\"C:/Main/nyu/ds/spotify52kData.csv\")\n",
    "#dfmain[['songNumber']] = dfmain[['songNumber']] + 1\n",
    "dfmain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "dfnum = dfmain[['duration', 'danceability', 'energy', 'loudness', 'speechiness',\n",
    "'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(15, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "features = ['duration', 'danceability', 'energy', 'loudness', 'speechiness',\n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "\n",
    "normal_params = {\n",
    "    'duration': {'mean': dfnum['duration'].mean(), 'std': dfnum['duration'].std()},\n",
    "    'duration': {'mean': dfnum['duration'].mean(), 'std': dfnum['duration'].std()},\n",
    "    'danceability': {'mean': dfnum['danceability'].mean(), 'std': dfnum['danceability'].std()},\n",
    "    'energy': {'mean': dfnum['energy'].mean(), 'std': dfnum['energy'].std()},\n",
    "    'loudness': {'mean': dfnum['loudness'].mean(), 'std': dfnum['loudness'].std()},\n",
    "    'speechiness': {'mean': dfnum['speechiness'].mean(), 'std': dfnum['speechiness'].std()},\n",
    "    'acousticness': {'mean': dfnum['acousticness'].mean(), 'std': dfnum['acousticness'].std()},\n",
    "    'instrumentalness': {'mean': dfnum['instrumentalness'].mean(), 'std': dfnum['instrumentalness'].std()},\n",
    "    'liveness': {'mean': dfnum['liveness'].mean(), 'std': dfnum['liveness'].std()},\n",
    "    'valence': {'mean': dfnum['valence'].mean(), 'std': dfnum['valence'].std()},\n",
    "    'tempo': {'mean': dfnum['tempo'].mean(), 'std': dfnum['tempo'].std()}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for i, feature in enumerate(features): \n",
    "    # Plot histogram\n",
    "    plt.hist(dfnum[feature], bins=30, density=True, alpha=0.9, color='blue', label='Sample Data')\n",
    "    \n",
    "    # Calculate normal distribution based on mean and standard deviation\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = norm.pdf(x, normal_params[feature]['mean'], normal_params[feature]['std'])\n",
    "    \n",
    "    # Plot normal distribution\n",
    "    plt.plot(x, p, 'k', linewidth=2, label='Normal Distribution')\n",
    "    \n",
    "    plt.xlabel(feature.capitalize())\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f'Histogram with Normal Distribution for {feature.capitalize()}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Perform Kolmogorov-Smirnov test\n",
    "    ks_stat, ks_pval = kstest(norm.pdf(x, normal_params[feature]['mean'], normal_params[feature]['std']), dfnum[feature],  method='exact')\n",
    "    print(f\"Kolmogorov-Smirnov test for {feature}: KS Statistic = {ks_stat}, p-value = {ks_pval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "filtered_df = dfmain[dfmain['duration'] / (1000. * 60) < 20.0]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.scatter(dfmain['popularity'], dfmain['duration'] / (1000. * 60), alpha=0.8)\n",
    "plt.title('Relationship between Popularity and Song Length')\n",
    "          \n",
    "#plt.scatter(filtered_df['popularity'], filtered_df['duration'] / (1000. * 60), alpha=0.8)\n",
    "#plt.title('Relationship between Popularity and Song Length (Duration < 20 min)')          \n",
    "          \n",
    "plt.ylabel('Duration (min)')\n",
    "plt.xlabel('Popularity')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(dfmain[['popularity', 'duration']].describe())\n",
    "#print(filtered_df[['popularity', 'duration']].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Assuming dfmain is your DataFrame\n",
    "# Filter the DataFrame to include only rows where duration is under 20 minutes\n",
    "#filtered_df = dfmain\n",
    "filtered_df = dfmain[(dfmain['duration'] / (1000. * 60) >= 12.00) & (dfmain['duration'] / (1000. * 60) <= 100000.00)]\n",
    "\n",
    "# Extracting the features and target variable\n",
    "X = filtered_df[['popularity']]\n",
    "y = filtered_df['duration'] / (1000. * 60)  # Converting duration to minutes\n",
    "\n",
    "#X = dfmain[['popularity']]\n",
    "#y = dfmain['duration'] / (1000. * 60)  # Converting duration to minutes\n",
    "\n",
    "\n",
    "# Ordinary Linear Regression\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X, y)\n",
    "linear_pred = linear_reg.predict(X)\n",
    "linear_r2 = r2_score(y, linear_pred)\n",
    "\n",
    "# Plot the relationship between popularity and song length for the filtered data\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(filtered_df['popularity'], y, alpha=0.8, label='Actual Data')\n",
    "#plt.scatter(dfmain['popularity'], y, alpha=0.8, label='Actual Data')\n",
    "plt.plot(X, linear_pred, color='red', label=f'Linear Regression (R-squared={linear_r2:.2f})')\n",
    "plt.title('Relationship between Popularity and Song Length (Duration > 12 min  )')\n",
    "plt.ylabel('Duration (min)')\n",
    "plt.xlabel('Popularity')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Display linear regression statistics\n",
    "linear_reg_stats = {\n",
    "    'Intercept': linear_reg.intercept_,\n",
    "    'Coefficient': linear_reg.coef_[0],\n",
    "    'R-squared': linear_r2,\n",
    "}\n",
    "print(\"Linear Regression Statistics:\")\n",
    "for key, value in linear_reg_stats.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Assuming dfmain is your DataFrame\n",
    "explicit_songs = dfmain[dfmain['explicit'] == 1]['popularity']\n",
    "non_explicit_songs = dfmain[dfmain['explicit'] == 0]['popularity']\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "mwu_stat, mwu_pval = mannwhitneyu(explicit_songs, non_explicit_songs, alternative='two-sided')\n",
    "\n",
    "print(f\"Mann-Whitney U Test: U Statistic = {mwu_stat}, p-value = {mwu_pval}\")\n",
    "\n",
    "explicit_median = np.median(explicit_songs)\n",
    "non_explicit_median = np.median(non_explicit_songs)\n",
    "explicit_percentiles = np.percentile(explicit_songs, [25, 75])  # 25th and 75th percentiles\n",
    "non_explicit_percentiles = np.percentile(non_explicit_songs, [25, 75])  # 25th and 75th percentiles\n",
    "\n",
    "\n",
    "# Create a boxplot with median and percentile annotations\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([explicit_songs, non_explicit_songs], labels=['Explicit', 'Non-Explicit'])\n",
    "plt.title('Popularity Comparison: Explicit vs Non-Explicit Songs')\n",
    "plt.xlabel('Explicitness')\n",
    "plt.ylabel('Popularity')\n",
    "plt.grid(True)\n",
    "\n",
    "# Annotate medians and percentiles\n",
    "plt.text(1, explicit_median, f'Median: {explicit_median}', ha='center', va='bottom', color='blue', fontweight='bold')\n",
    "plt.text(2, non_explicit_median, f'Median: {non_explicit_median}', ha='center', va='bottom', color='blue', fontweight='bold')\n",
    "plt.text(1, explicit_percentiles[0], f'25th Percentile: {explicit_percentiles[0]}', ha='center', va='top', color='red')\n",
    "plt.text(1, explicit_percentiles[1], f'75th Percentile: {explicit_percentiles[1]}', ha='center', va='bottom', color='red')\n",
    "plt.text(2, non_explicit_percentiles[0], f'25th Percentile: {non_explicit_percentiles[0]}', ha='center', va='top', color='red')\n",
    "plt.text(2, non_explicit_percentiles[1], f'75th Percentile: {non_explicit_percentiles[1]}', ha='center', va='bottom', color='red')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Assuming dfmain is your DataFrame\n",
    "majorkey_songs = dfmain[dfmain['mode'] == 1]['popularity']\n",
    "minorkey_songs = dfmain[dfmain['mode'] == 0]['popularity']\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "mwus_stat, mwus_pval = mannwhitneyu(majorkey_songs, minorkey_songs, alternative='two-sided')\n",
    "\n",
    "print(f\"Mann-Whitney U Test: U Statistic = {mwus_stat}, p-value = {mwus_pval}\")\n",
    "\n",
    "makey_median = np.median(majorkey_songs)\n",
    "mikey_median = np.median(minorkey_songs)\n",
    "makey_percentiles = np.percentile(majorkey_songs, [25, 75])  # 25th and 75th percentiles\n",
    "mikey_percentiles = np.percentile(minorkey_songs, [25, 75])  # 25th and 75th percentiles\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([majorkey_songs, minorkey_songs], labels=['Major Key', 'Minor Key'])\n",
    "plt.title('Popularity Comparison: Major Key vs Minor Key Songs')\n",
    "plt.xlabel('Type of Key')\n",
    "plt.ylabel('Popularity')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.text(1, makey_median, f'Median: {makey_median}', ha='center', va='bottom', color='blue', fontweight='bold')\n",
    "plt.text(2, makey_median, f'Median: {mikey_median}', ha='center', va='bottom', color='blue', fontweight='bold')\n",
    "plt.text(1, makey_percentiles[0], f'25th Percentile: {makey_percentiles[0]}', ha='center', va='top', color='red')\n",
    "plt.text(1, makey_percentiles[1], f'75th Percentile: {makey_percentiles[1]}', ha='center', va='bottom', color='red')\n",
    "plt.text(2, mikey_percentiles[0], f'25th Percentile: {mikey_percentiles[0]}', ha='center', va='top', color='red')\n",
    "plt.text(2, mikey_percentiles[1], f'75th Percentile: {mikey_percentiles[1]}', ha='center', va='bottom', color='red')\n",
    " \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Assuming dfmain is your DataFrame\n",
    "energy = dfmain['energy']\n",
    "loudness = dfmain['loudness']\n",
    "\n",
    "#energy = (dfmain[2 ** (dfmain['loudness'])<5]['energy'])\n",
    "\n",
    "#loudness = 2 ** (dfmain[2 **(dfmain['loudness'])<5]['loudness'])\n",
    "\n",
    "# Define linear regression function\n",
    "def linear_regression(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "# Perform linear regression\n",
    "popt_lin, _ = curve_fit(linear_regression, energy, loudness)\n",
    "y_lin_pred = linear_regression(energy, *popt_lin)\n",
    "r2_lin = r2_score(loudness, y_lin_pred)\n",
    "\n",
    "# Get the coefficients\n",
    "a = popt_lin[0]\n",
    "b = popt_lin[1]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(energy, loudness, alpha=0.8, label='Data')\n",
    "plt.title('Relationship between Energy and Loudness')\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Loudness (dB)')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot linear regression line\n",
    "plt.plot(energy, y_lin_pred, color='red', label=f'Line of Best Fit (R-squared = {r2_lin:.2f}): y = {a:.2f}x + {b:.2f}')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Assuming dfmain is your DataFrame\n",
    "energy = dfmain['energy']\n",
    "loudness = dfmain['loudness']\n",
    "\n",
    "# Define linear regression function\n",
    "def linear_regression(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "# Define logarithmic regression function\n",
    "def logarithmic_regression(x, a, b):\n",
    "    return a * np.log(x) + b\n",
    "\n",
    "# Perform linear regression\n",
    "popt_lin, _ = curve_fit(linear_regression, energy, loudness)\n",
    "y_lin_pred = linear_regression(energy, *popt_lin)\n",
    "r2_lin = r2_score(loudness, y_lin_pred)\n",
    "\n",
    "# Perform logarithmic regression\n",
    "popt_log, _ = curve_fit(logarithmic_regression, energy, loudness)\n",
    "y_log_pred = logarithmic_regression(energy, *popt_log)\n",
    "r2_log = r2_score(loudness, y_log_pred)\n",
    "\n",
    "# Get the coefficients for linear regression\n",
    "a_lin = popt_lin[0]\n",
    "b_lin = popt_lin[1]\n",
    "\n",
    "# Get the coefficients for logarithmic regression\n",
    "a_log = popt_log[0]\n",
    "b_log = popt_log[1]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(energy, loudness, alpha=0.8, label='Data')\n",
    "plt.title('Relationship between Energy and Loudness')\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Loudness (dB)')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot linear regression line\n",
    "plt.plot(energy, y_lin_pred, color='red', label=f'Linear Fit (R-squared = {r2_lin:.2f}): y = {a_lin:.2f}x + {b_lin:.2f}')\n",
    "\n",
    "# Plot logarithmic regression line\n",
    "plt.plot(sorted(energy), logarithmic_regression(sorted(energy), *popt_log), color='white', label=f'Logarithmic Fit (R-squared = {r2_log:.2f}): y = {a_log:.2f}ln(x) + {b_log:.2f}')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "X = dfmain[['duration', 'danceability', 'energy', 'loudness', 'speechiness',\n",
    "        'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y = dfmain['popularity']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Fit linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared Score:\", r2)\n",
    "print(\"Coefficients:\", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define features and target\n",
    "X = dfmain[['duration', 'danceability', 'energy', 'loudness', 'speechiness',\n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y = dfmain['popularity']\n",
    "\n",
    "# Initialize lists to store results\n",
    "mse_values = []\n",
    "r2_values = []\n",
    "\n",
    "# Loop through each feature and perform regression\n",
    "for feature_name in X.columns:\n",
    "    # Extract feature as a single-column DataFrame\n",
    "    X_feature = X[[feature_name]]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_feature, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    # Fit linear regression model\n",
    "    model_feature = LinearRegression()\n",
    "    model_feature.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_feature = model_feature.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse_feature = mean_squared_error(y_test, y_pred_feature)\n",
    "    r2_feature = r2_score(y_test, y_pred_feature)\n",
    "    \n",
    "    # Append MSE and R-squared values to lists\n",
    "    mse_values.append(mse_feature)\n",
    "    r2_values.append(r2_feature)\n",
    "     \n",
    "    # Plot scatter plot and line of best fit for each feature\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X_test, y_test, color='blue', label='Actual Data')\n",
    "    plt.plot(X_test, y_pred_feature, color='red', label='Line of Best Fit')\n",
    "    plt.title(f'Regression of {feature_name.capitalize()} with Popularity')\n",
    "    plt.xlabel(feature_name.capitalize())\n",
    "    plt.ylabel('Popularity')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print MSE and R-squared values for each feature\n",
    "    print(f\"Mean Squared Error ({feature_name.capitalize()}): {mse_feature:.2f}\")\n",
    "    print(f\"R-squared Score ({feature_name.capitalize()}): {r2_feature:.2f}\\n\")\n",
    "\n",
    "# Print overall MSE and R-squared values\n",
    "print(\"Overall Mean Squared Error:\", np.mean(mse_values))\n",
    "print(\"Overall R-squared Score:\", np.mean(r2_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define features and target\n",
    "X = dfmain[['duration', 'danceability', 'energy', 'loudness', 'speechiness',\n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "y = dfmain['popularity']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Fit linear regression model\n",
    "model_all_features = LinearRegression()\n",
    "model_all_features.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_all_features = model_all_features.predict(X_test)\n",
    "\n",
    "# Evaluate the linear regression model\n",
    "mse_all_features = mean_squared_error(y_test, y_pred_all_features)\n",
    "r2_all_features = r2_score(y_test, y_pred_all_features)\n",
    "\n",
    "print(\"Linear Regression - Mean Squared Error (All Features):\", mse_all_features)\n",
    "print(\"Linear Regression - R-squared Score (All Features):\", r2_all_features)\n",
    "\n",
    "# Fit Ridge regression model\n",
    "model_ridge = Ridge(alpha=0.5)  # You can adjust the alpha value\n",
    "model_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using Ridge regression\n",
    "y_pred_ridge = model_ridge.predict(X_test)\n",
    "\n",
    "# Evaluate the Ridge regression model\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "print(\"\\nRidge Regression - Mean Squared Error:\", mse_ridge)\n",
    "print(\"Ridge Regression - R-squared Score:\", r2_ridge)\n",
    "\n",
    "# Fit Lasso regression model\n",
    "model_lasso = Lasso(alpha=0.1)  # You can adjust the alpha value\n",
    "model_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using Lasso regression\n",
    "y_pred_lasso = model_lasso.predict(X_test)\n",
    "\n",
    "# Evaluate the Lasso regression model\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "print(\"\\nLasso Regression - Mean Squared Error:\", mse_lasso)\n",
    "print(\"Lasso Regression - R-squared Score:\", r2_lasso)\n",
    "\n",
    "'''# Fit TensorFlow linear model (single-layer neural network)\n",
    "model_tf = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, input_shape=[X_train.shape[1]])\n",
    "])\n",
    "model_tf.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "model_tf.fit(X_train, y_train, epochs=100, verbose=0)  # You can adjust the number of epochs\n",
    "\n",
    "# Make predictions using TensorFlow model\n",
    "y_pred_tf = model_tf.predict(X_test).flatten()\n",
    "\n",
    "# Evaluate the TensorFlow model\n",
    "mse_tf = mean_squared_error(y_test, y_pred_tf)\n",
    "r2_tf = r2_score(y_test, y_pred_tf)\n",
    "\n",
    "print(\"\\nTensorFlow Linear Model - Mean Squared Error:\", mse_tf)\n",
    "print(\"TensorFlow Linear Model - R-squared Score:\", r2_tf)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(dfnum)\n",
    "\n",
    "# Get the explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "total_variance_explained = explained_variance_ratio.sum()\n",
    "\n",
    "print(\"Explained Variance Ratio for Each Principal Component:\", explained_variance_ratio)\n",
    "print(\"Total Variance Explained by Important Principal Components:\", explained_variance_ratio[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from numpy.linalg import eig\n",
    "\n",
    "# Calculate covariance matrix\n",
    "covariance_matrix = np.cov(dfnum.T)\n",
    "\n",
    "# Compute eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = eig(covariance_matrix)\n",
    "\n",
    "# Apply Kaiser criterion\n",
    "important_eigenvectors = eigenvectors[:, eigenvalues > 1]\n",
    "important_eigenvalues = eigenvalues[eigenvalues > 1]\n",
    "\n",
    "\n",
    "# Compute the total variance explained by important principal components\n",
    "total_variance_explained = np.sum(important_eigenvalues) / np.sum(eigenvalues)\n",
    "\n",
    "print(\"Eigenvalues:\")\n",
    "print(important_eigenvalues)\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(important_eigenvectors)\n",
    "print(\"\\nTotal Variance Explained by Important Principal Components:\", total_variance_explained)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare the data\n",
    "X = dfmain[['valence']]  # Features\n",
    "y = dfmain['mode']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Build and train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test.tolist(), y_pred.tolist())\n",
    "conf_matrix = confusion_matrix(y_test.tolist(), y_pred.tolist())\n",
    "class_report = classification_report(y_test.tolist(), y_pred.tolist())\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "# Plot the logistic regression curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X['valence'], y=y, hue=y, palette='viridis')\n",
    "plt.xlabel('Valence')\n",
    "plt.ylabel('Mode (0: Minor, 1: Major)')\n",
    "plt.title('Logistic Regression for Key Prediction')\n",
    "plt.legend(['Minor Key', 'Major Key'], loc='upper right')\n",
    "\n",
    "# Plot the logistic regression curve\n",
    "x_values = np.linspace(X['valence'].min(), X['valence'].max(), 100)\n",
    "y_prob = model.predict_proba(x_values.reshape(-1, 1))[:, 1]  # Probability of being in major key\n",
    "plt.plot(x_values, y_prob, color='red')\n",
    "\n",
    "plt.show()\n",
    "print(y_test.tolist())\n",
    "print(y_pred.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Extract TP, FP, TN, FN from the confusion matrix\n",
    "TN = conf_matrix[0, 0]\n",
    "FP = conf_matrix[0, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "TP = conf_matrix[1, 1]\n",
    "\n",
    "print(\"True Negatives (TN):\", TN)\n",
    "print(\"False Positives (FP):\", FP)\n",
    "print(\"False Negatives (FN):\", FN)\n",
    "print(\"True Positives (TP):\", TP)\n",
    "\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Probability of being in major key\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"AUC:\", roc_auc)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming dfnum contains all numerical features and 'mode' column for target variable\n",
    "\n",
    "# Prepare the data\n",
    "X = dfnum  # Features\n",
    "y = dfmain['mode']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=seed)\n",
    "\n",
    "# Initialize an empty dictionary to store results for each feature\n",
    "results = {}\n",
    "\n",
    "# Loop through each feature and build logistic regression models\n",
    "for col in X.columns:\n",
    "    # Extract the feature\n",
    "    X_feature = X[[col]]\n",
    "    \n",
    "    # Split the feature data into training and testing sets\n",
    "    X_train_feature, X_test_feature = train_test_split(X_feature, test_size=0.5, random_state=seed)\n",
    "    \n",
    "    # Build and train the logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_feature, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_feature)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Store results in the dictionary\n",
    "    results[col] = {\n",
    "        'accuracy': accuracy,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'classification_report': class_report,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "    # Plot the logistic regression curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_feature[col], y=y, hue=y, palette='viridis')\n",
    "    plt.xlabel(col.capitalize())\n",
    "    plt.ylabel('Mode (0: Minor, 1: Major)')\n",
    "    plt.title(f'Logistic Regression for Key Prediction using {col.capitalize()}')\n",
    "    plt.legend(['Minor Key', 'Major Key'], loc='upper right')\n",
    "\n",
    "    # Plot the logistic regression curve\n",
    "    x_values = np.linspace(X_feature[col].min(), X_feature[col].max(), 100)\n",
    "    y_prob = model.predict_proba(x_values.reshape(-1, 1))[:, 1]  # Probability of being in major key\n",
    "    plt.plot(x_values, y_prob, color='red')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Print results\n",
    "for feature, result in results.items():\n",
    "    print(f\"Feature: {feature.capitalize()}\")\n",
    "    print(\"Accuracy:\", result['accuracy'])\n",
    "    print(\"Confusion Matrix:\\n\", result['confusion_matrix'])\n",
    "    print(\"Classification Report:\\n\", result['classification_report'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming dfnum contains all numerical features and 'mode' column for target variable\n",
    "\n",
    "# Prepare the data\n",
    "X = dfnum  # Features\n",
    "y = dfmain['mode']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Initialize an empty dictionary to store results for each feature\n",
    "results = {}\n",
    "\n",
    "# Loop through each feature and build logistic regression models\n",
    "for col in X.columns:\n",
    "    # Extract the feature\n",
    "    X_feature = X[[col]]\n",
    "    \n",
    "    # Split the feature data into training and testing sets\n",
    "    X_train_feature, X_test_feature, y_train, y_test = train_test_split(X_feature, y, test_size=0.5, random_state=seed)\n",
    "    \n",
    "    # Build and train the logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_feature, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_feature)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Calculate ROC curve and AUROC\n",
    "    y_prob = model.predict_proba(X_test_feature)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    # Store results in the dictionary\n",
    "    results[col] = {\n",
    "        'accuracy': accuracy,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'classification_report': class_report,\n",
    "        'roc_curve': (fpr, tpr),\n",
    "        'roc_auc': roc_auc,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUROC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve for {col.capitalize()}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "# Print results\n",
    "for feature, result in results.items():\n",
    "    print(f\"Feature: {feature.capitalize()}\")\n",
    "    print(\"Accuracy:\", result['accuracy'])\n",
    "    print(\"Confusion Matrix:\\n\", result['confusion_matrix'])\n",
    "    print(\"Classification Report:\\n\", result['classification_report'])\n",
    "    print(\"AUROC:\", result['roc_auc'])\n",
    "    print(\"ROC Curve Coordinates:\", result['roc_curve'])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming dfmain is your DataFrame containing the song data\n",
    "\n",
    "# Convert genre label to binary numerical label (classical or not)\n",
    "dfmain['is_classical'] = dfmain['track_genre'].apply(lambda x: 1 if x == 'classical' else 0)\n",
    "\n",
    "# Prepare the data\n",
    "X_duration = dfmain[['duration']]  # Features\n",
    "y_duration = dfmain['is_classical']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_duration, X_test_duration, y_train_duration, y_test_duration = train_test_split(X_duration, y_duration, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Build and train the logistic regression model based on duration\n",
    "model_duration = LogisticRegression()\n",
    "model_duration.fit(X_train_duration, y_train_duration)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_duration = model_duration.predict(X_test_duration)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_duration = accuracy_score(y_test_duration, y_pred_duration)\n",
    "print(\"Accuracy for Duration Predictor:\", accuracy_duration)\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test_duration, model_duration.predict_proba(X_test_duration)[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot logistic regression curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_duration, y_duration, color='blue', alpha=0.5)\n",
    "plt.xlabel('Duration')\n",
    "plt.ylabel('Is Classical (1: Yes, 0: No)')\n",
    "plt.title('Logistic Regression Curve for Classical Music Prediction based on Duration')\n",
    "x_values = np.linspace(X_duration.min(), X_duration.max(), 100)\n",
    "y_prob = model_duration.predict_proba(x_values.reshape(-1, 1))[:, 1]\n",
    "plt.plot(x_values, y_prob, color='red', label='Logistic Regression Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_duration, y_pred_duration)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define features and target\n",
    "X = np.matmul((dfnum.values), important_eigenvectors)\n",
    "y = dfmain['is_classical'] \n",
    "print(important_eigenvectors.shape, (dfnum.values).shape, x.shape, y.shape)\n",
    "# Assuming dfnum_pca is your DataFrame containing PCA components\n",
    "# X_pca should contain the PCA components (3 principal components) as features\n",
    "# Assuming dfnum is your DataFrame with numerical data\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Build and train the logistic regression model based on PCA components\n",
    "model_pca = LogisticRegression()\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_pca = model_pca.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "print(\"Accuracy for PCA Predictor:\", accuracy_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define features and target\n",
    "X = np.matmul(dfnum.values, important_eigenvectors)\n",
    "y = dfmain['is_classical']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Build and train the logistic regression model based on PCA components\n",
    "model_pca = LogisticRegression()\n",
    "model_pca.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_pca.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_pca = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy for PCA Predictor:\", accuracy_pca)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, palette='viridis')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('Logistic Regression for Classification')\n",
    "plt.legend(['Not Classical', 'Classical'], loc='upper right')\n",
    "\n",
    "'''# Plot the logistic regression decision boundary\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "Z = model_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, alpha=0.4, cmap='viridis')'''\n",
    "# Plot the ROC curve\n",
    "y_prob = model_pca.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'Random' could not be imported from 'c:\\Main\\nyu\\ds\\random.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming dfmain is your DataFrame containing the song data\n",
    "\n",
    "# Convert genre label to binary numerical label (classical or not)or\n",
    "dfmain['is_electronic'] = dfmain['track_genre'].apply(lambda x: 1 if x == 'electronic' or  x == 'anime' or x == 'chill' or x == 'club' or x == 'detroit-techno' or x == 'dubstep' or x == 'edm' else 0)\n",
    "                                                      \n",
    "\n",
    "# Prepare the data\n",
    "X_duration = dfmain[['acousticness']]  # Features\n",
    "y_duration = dfmain['is_electronic']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_duration, X_test_duration, y_train_duration, y_test_duration = train_test_split(X_duration, y_duration, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Build and train the logistic regression model based on duration\n",
    "model_duration = LogisticRegression()\n",
    "model_duration.fit(X_train_duration, y_train_duration)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_duration = model_duration.predict(X_test_duration)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_duration = accuracy_score(y_test_duration, y_pred_duration)\n",
    "print(\"Accuracy for Duration Predictor:\", accuracy_duration)\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test_duration, model_duration.predict_proba(X_test_duration)[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot logistic regression curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_duration, y_duration, color='blue', alpha=0.5)\n",
    "plt.xlabel('Acousticness')\n",
    "plt.ylabel('Is Classical (1: Yes, 0: No)')\n",
    "plt.title('Logistic Regression Curve for Electronic-Sounding Music Prediction based on Acousticness')\n",
    "x_values = np.linspace(X_duration.min(), X_duration.max(), 100)\n",
    "y_prob = model_duration.predict_proba(x_values.reshape(-1, 1))[:, 1]\n",
    "plt.plot(x_values, y_prob, color='red', label='Logistic Regression Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_duration, y_pred_duration)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
